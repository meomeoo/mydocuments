{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis = [i for i in range(32)]\n",
    "dataFrame = pd.DataFrame(pd.read_csv(filepath_or_buffer = 'data.csv', usecols = lis))\n",
    "for i in range(568):\n",
    "    if dataFrame['diagnosis'].iloc[i] == M :\n",
    "        dataFrame['diagnosis'].iloc[i] = 1\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lables = dataFrame['diagnosis']\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co benh: 212\n",
      "khong co benh: 357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()  # Load the label encoder\n",
    "lables = le.fit_transform(lables)  # Encode the string target features into integers\n",
    "features = dataFrame.drop(['id', 'diagnosis'], axis=1)\n",
    "print('co benh:', lables.tolist().count(1))\n",
    "print('khong co benh:', lables.tolist().count(0))\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
       "         2.75062224,  1.93701461],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
       "        -0.24388967,  0.28118999],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
       "         1.152255  ,  0.20139121],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
       "        -1.10454895, -0.31840916],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
       "         1.91908301,  2.21963528],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
       "        -0.04813821, -0.75120669]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  # Load the standard scaler\n",
    "sc.fit(features)  # Compute the mean and standard deviation of the feature data\n",
    "features = sc.transform(features)  # Scale the feature data to be of mean 0 and variance 1\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, lables, test_size=.3, random_state=1)  # Split the dataset into 30% testing, and 70% training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x >= threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "def plot_auc(labels, probs):\n",
    "    ## Compute the false positive rate, true positive rate\n",
    "    ## and threshold along with the AUC\n",
    "    fpr, tpr, threshold = sklm.roc_curve(labels, probs[:,1])\n",
    "    auc = sklm.auc(fpr, tpr)\n",
    "    \n",
    "    ## Plot the result\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "log = LogisticRegression(penalty='none', solver = 'lbfgs')\n",
    "\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = log.predict(X_train)\n",
    "prediction_test = log.predict(X_test)\n",
    "probabilities = log.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       103                 5\n",
      "Actual negative         3                60\n",
      "\n",
      "Accuracy        0.95\n",
      "AUC             0.95\n",
      "Macro precision 0.95\n",
      "Macro recall    0.95\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      108            63\n",
      "Precision    0.97          0.92\n",
      "Recall       0.95          0.95\n",
      "F1           0.96          0.94\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_metrics(y_test, probabilities, 0.5)    \n",
    "plot_auc(y_test, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitc43054c6a3a4445ea67e973b0ee93d75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
